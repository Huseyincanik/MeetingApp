"""
ElevenLabs Speech-to-Text Service
ElevenLabs Python SDK kullanarak konuÅŸma tanÄ±ma ve transkript oluÅŸturma servisi
KiÅŸi ayrÄ±mÄ± (speaker diarization) desteÄŸi ile profesyonel toplantÄ± transkriptleri

KURULUM:
1. .env dosyasÄ±na ELEVENLABS_API_KEY ekleyin
2. pip install elevenlabs
3. Model ID: "scribe_v1" (ÅŸu an iÃ§in tek desteklenen model)

KÄ°ÅÄ° AYRIMI (SPEAKER DIARIZATION):
- ElevenLabs iÃ§in speaker diarization varsayÄ±lan olarak aktif (diarize=True)
- Multi-channel modunda diarize=False olmalÄ± (her kanal zaten bir konuÅŸmacÄ±)
- API kendi diarization saÄŸlÄ±yor, harici pyannote sonuÃ§larÄ± ile birleÅŸtirilebilir
"""
import os
import asyncio
from io import BytesIO
from typing import List, Dict, Optional
from elevenlabs.client import ElevenLabs
from ..config import settings


class ElevenLabsService:
    """ElevenLabs Speech-to-Text servisi - KiÅŸi ayrÄ±mÄ± destekli"""
    
    def __init__(self):
        # ElevenLabs API key - config'den veya environment variable'dan alÄ±nacak
        self.api_key = settings.elevenlabs_api_key or os.getenv("ELEVENLABS_API_KEY", "")
        self.model_id = settings.elevenlabs_model_id or os.getenv("ELEVENLABS_MODEL_ID", "scribe_v1")
        
        if not self.api_key:
            raise RuntimeError("ElevenLabs API key bulunamadÄ±. LÃ¼tfen .env dosyasÄ±na ELEVENLABS_API_KEY ekleyin.")
        
        # ElevenLabs client oluÅŸtur
        self.client = ElevenLabs(api_key=self.api_key)
        print(f"âœ… ElevenLabs client oluÅŸturuldu (Model: {self.model_id})")
    
    def _get_language_code(self, language: str) -> Optional[str]:
        """Dil kodunu ElevenLabs formatÄ±na Ã§evir"""
        language_map = {
            "tr": "tur",  # TÃ¼rkÃ§e
            "en": "eng",  # Ä°ngilizce
        }
        return language_map.get(language, None)  # None = otomatik algÄ±lama
    
    async def transcribe_audio(
        self,
        audio_path: str,
        model_name: str = "elevenlabs",
        language: str = "tr",
        enable_speaker_diarization: bool = True,  # ElevenLabs iÃ§in varsayÄ±lan olarak aktif
        speaker_segments: Optional[List[Dict]] = None
    ) -> List[Dict]:
        """
        Ses dosyasÄ±nÄ± ElevenLabs SDK kullanarak transkript et
        
        Args:
            audio_path: Ä°ÅŸlenecek ses dosyasÄ± yolu
            model_name: Model adÄ± (elevenlabs)
            language: Dil kodu (tr, en)
            enable_speaker_diarization: KiÅŸi ayrÄ±mÄ± aktif mi
            speaker_segments: Ã–nceden hesaplanmÄ±ÅŸ konuÅŸmacÄ± segmentleri (opsiyonel)
        
        Returns:
            Transkript segmentleri listesi (speaker bilgisi ile)
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"Ses dosyasÄ± bulunamadÄ±: {audio_path}")
        
        # Dosya bilgilerini kontrol et
        file_size = os.path.getsize(audio_path)
        print(f"ğŸ“Š ElevenLabs: Dosya boyutu: {file_size} bytes ({file_size / 1024:.2f} KB)")
        
        if file_size < 1000:  # 1KB'dan kÃ¼Ã§Ã¼kse
            print("âš ï¸  ElevenLabs: Dosya Ã§ok kÃ¼Ã§Ã¼k, muhtemelen boÅŸ")
            return [{
                "text": "",
                "start": 0.0,
                "end": 0.0,
                "speaker_id": None,
                "speaker_label": None
            }]
        
        # Dil kodunu ElevenLabs formatÄ±na Ã§evir
        language_code = self._get_language_code(language)
        print(f"ğŸŒ ElevenLabs: Dil: {language} -> {language_code or 'otomatik algÄ±lama'}")
        
        try:
            # Ses dosyasÄ±nÄ± oku
            print(f"ğŸ“‚ ElevenLabs: Ses dosyasÄ± okunuyor: {audio_path}")
            with open(audio_path, 'rb') as audio_file:
                audio_data = BytesIO(audio_file.read())
            
            # ElevenLabs API'ye istek gÃ¶nder
            print(f"ğŸŒ ElevenLabs: API'ye istek gÃ¶nderiliyor...")
            print(f"ğŸ“‹ ElevenLabs: Model ID: {self.model_id}, Diarization: {enable_speaker_diarization}")
            
            # SDK metodunu async executor'da Ã§alÄ±ÅŸtÄ±r
            def _transcribe():
                return self.client.speech_to_text.convert(
                    file=audio_data,
                    model_id=self.model_id,
                    tag_audio_events=True,  # Ses olaylarÄ±nÄ± etiketle (gÃ¼lme, alkÄ±ÅŸ vb.)
                    language_code=language_code,  # None ise otomatik algÄ±lama
                    diarize=enable_speaker_diarization,  # KiÅŸi ayrÄ±mÄ±
                    timestamps_granularity='word'  # Kelime bazlÄ± zaman damgalarÄ±
                )
            
            # Senkron SDK metodunu async executor'da Ã§alÄ±ÅŸtÄ±r
            try:
                transcription = await asyncio.to_thread(_transcribe)
            except AttributeError:
                # Python < 3.9 iÃ§in alternatif
                loop = asyncio.get_event_loop()
                transcription = await loop.run_in_executor(None, _transcribe)
            
            print(f"âœ… ElevenLabs: Transkript alÄ±ndÄ±")
            
            # API yanÄ±tÄ±nÄ± iÅŸle
            segments = self._process_api_response(
                transcription, 
                enable_speaker_diarization,
                speaker_segments
            )
            
            return segments
        
        except Exception as e:
            error_msg = f"ElevenLabs iÅŸleme hatasÄ±: {e}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            raise RuntimeError(error_msg)
    
    def _process_api_response(
        self,
        transcription_response,
        enable_speaker_diarization: bool,
        speaker_segments: Optional[List[Dict]] = None
    ) -> List[Dict]:
        """
        ElevenLabs API yanÄ±tÄ±nÄ± iÅŸle ve segmentlere dÃ¶nÃ¼ÅŸtÃ¼r
        
        ElevenLabs API'si SpeechToTextChunkResponseModel dÃ¶ndÃ¼rÃ¼r:
        - transcription.text: Tam metin
        - transcription.words: Kelime listesi (word objeleri)
        - transcription.channel_index: Kanal index'i (multi-channel iÃ§in)
        - Her word: text, start, end, speaker_id (varsa), type
        """
        all_words = []
        
        # Result formatÄ±nÄ± kontrol et
        # ElevenLabs API'si farklÄ± formatlar dÃ¶ndÃ¼rebilir:
        # 1. Tek bir SpeechToTextChunkResponseModel objesi (text, words direkt)
        # 2. Dict formatÄ±nda {'transcripts': [...]}
        # 3. Liste formatÄ±nda [transcript1, transcript2, ...]
        
        transcripts = []
        
        if isinstance(transcription_response, list):
            # Liste formatÄ±nda
            transcripts = transcription_response
        elif isinstance(transcription_response, dict):
            # Dict formatÄ±nda
            if 'transcripts' in transcription_response:
                transcripts = transcription_response['transcripts']
            elif 'words' in transcription_response:
                # Tek bir transcript dict formatÄ±nda
                transcripts = [transcription_response]
            else:
                transcripts = []
        else:
            # Obje formatÄ±nda (SpeechToTextChunkResponseModel)
            # EÄŸer 'transcripts' attribute'u varsa kullan
            if hasattr(transcription_response, 'transcripts') and transcription_response.transcripts:
                transcripts = transcription_response.transcripts
            elif hasattr(transcription_response, 'words') or hasattr(transcription_response, 'text'):
                # Tek bir transcript objesi - direkt kullan
                transcripts = [transcription_response]
            else:
                transcripts = []
        
        # EÄŸer transcripts boÅŸsa, hata mesajÄ± ver
        if not transcripts:
            print("âš ï¸  Transcripts boÅŸ! Result yapÄ±sÄ±nÄ± kontrol ediyorum...")
            print(f"   Result tipi: {type(transcription_response)}")
            if hasattr(transcription_response, '__dict__'):
                print(f"   Result attributes: {transcription_response.__dict__.keys()}")
            return []
        
        # TÃ¼m kanallardan kelimeleri topla
        for transcript in transcripts:
            # Transcript dict veya obje olabilir
            if isinstance(transcript, dict):
                channel_index = transcript.get('channel_index', 0)
                words = transcript.get('words', [])
            else:
                channel_index = getattr(transcript, 'channel_index', 0)
                words = getattr(transcript, 'words', []) or []
            
            if not words:
                print(f"âš ï¸  Transcript'te kelime bulunamadÄ± (channel: {channel_index})")
                continue
            
            for word in words:
                # Word dict veya obje olabilir
                if isinstance(word, dict):
                    word_type = word.get('type', 'word')
                    word_text = word.get('text', '')
                    word_start = word.get('start', 0)
                    word_end = word.get('end', 0)
                    word_speaker_id = word.get('speaker_id', None)
                else:
                    word_type = getattr(word, 'type', 'word')
                    word_text = getattr(word, 'text', '')
                    word_start = getattr(word, 'start', 0)
                    word_end = getattr(word, 'end', 0)
                    word_speaker_id = getattr(word, 'speaker_id', None)
                
                # Sadece 'word' tipinde olanlarÄ± al
                if word_type == 'word' and word_text:
                    # Multi-channel modunda speaker_id kanal index'ine gÃ¶re atanÄ±r
                    speaker_id = word_speaker_id
                    # EÄŸer speaker_id yoksa ama channel varsa, channel'Ä± speaker olarak kullan
                    if speaker_id is None and channel_index is not None:
                        speaker_id = f"channel_{channel_index}"
                    # EÄŸer hala speaker_id yoksa, varsayÄ±lan speaker kullan
                    if speaker_id is None:
                        speaker_id = "speaker_0"
                    
                    all_words.append({
                        'text': word_text,
                        'start': word_start,
                        'end': word_end,
                        'speaker_id': speaker_id,
                        'channel': channel_index
                    })
        
        if not all_words:
            print("âš ï¸  HiÃ§ kelime bulunamadÄ±! Transkript boÅŸ olabilir.")
            return []
        
        # Zaman damgasÄ±na gÃ¶re sÄ±rala
        all_words.sort(key=lambda w: w['start'])
        
        # KonuÅŸmacÄ±ya gÃ¶re ardÄ±ÅŸÄ±k kelimeleri grupla (segmentlere dÃ¶nÃ¼ÅŸtÃ¼r)
        segments = []
        current_speaker = None
        current_text = []
        current_start_time = 0.0
        current_end_time = 0.0
        
        for word in all_words:
            speaker = word['speaker_id'] if word['speaker_id'] is not None else 'speaker_unknown'
            
            # KonuÅŸmacÄ± deÄŸiÅŸti mi?
            if speaker != current_speaker:
                # Ã–nceki konuÅŸmacÄ±nÄ±n segmentini kaydet
                if current_text:
                    segments.append({
                        'text': ' '.join(current_text),
                        'start': current_start_time,
                        'end': current_end_time,
                        'speaker_id': current_speaker,
                        'speaker_label': self._get_speaker_label(current_speaker)
                    })
                # Yeni konuÅŸmacÄ± baÅŸlat
                current_speaker = speaker
                current_text = [word['text']]
                current_start_time = word['start']
                current_end_time = word['end']
            else:
                # AynÄ± konuÅŸmacÄ± devam ediyor
                current_text.append(word['text'])
                current_end_time = word['end']  # Son kelimenin bitiÅŸ zamanÄ±nÄ± gÃ¼ncelle
        
        # Son konuÅŸmacÄ±nÄ±n segmentini ekle
        if current_text:
            segments.append({
                'text': ' '.join(current_text),
                'start': current_start_time,
                'end': current_end_time,
                'speaker_id': current_speaker,
                'speaker_label': self._get_speaker_label(current_speaker)
            })
        
        # EÄŸer speaker_segments varsa ve API'den speaker bilgisi gelmemiÅŸse, eÅŸleÅŸtir
        if enable_speaker_diarization and speaker_segments and not any(seg.get("speaker_id") for seg in segments):
            print("ğŸ”„ ElevenLabs: Harici speaker diarization sonuÃ§larÄ± ile eÅŸleÅŸtiriliyor...")
            for segment in segments:
                for speaker_seg in speaker_segments:
                    if (segment["start"] >= speaker_seg["start"] and 
                        segment["end"] <= speaker_seg["end"]):
                        segment["speaker_id"] = speaker_seg.get("speaker_id")
                        segment["speaker_label"] = speaker_seg.get("speaker_label")
                        break
        
        # Speaker bilgisi yoksa ve diarization aktifse, label'larÄ± oluÅŸtur
        if enable_speaker_diarization:
            for segment in segments:
                if segment.get("speaker_id") and not segment.get("speaker_label"):
                    segment["speaker_label"] = self._get_speaker_label(segment["speaker_id"])
        
        print(f"âœ… ElevenLabs: {len(segments)} transkript segmenti oluÅŸturuldu")
        return segments
    
    def _get_speaker_label(self, speaker_id: str) -> str:
        """Speaker ID'yi okunabilir etikete Ã§evir"""
        if not speaker_id or speaker_id == 'speaker_unknown':
            return None
        
        try:
            # channel_0, channel_1 formatÄ±
            if speaker_id.startswith('channel_'):
                channel_num = int(speaker_id.split('_')[1])
                return f"KonuÅŸmacÄ± {channel_num + 1}"
            # speaker_0, speaker_1 formatÄ±
            elif speaker_id.startswith('speaker_'):
                speaker_num = int(speaker_id.split('_')[1])
                return f"KonuÅŸmacÄ± {speaker_num + 1}"
            # Direkt sayÄ±
            elif speaker_id.isdigit():
                return f"KonuÅŸmacÄ± {int(speaker_id) + 1}"
            else:
                return speaker_id
        except:
            return speaker_id
