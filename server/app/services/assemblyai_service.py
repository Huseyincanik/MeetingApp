"""
AssemblyAI Speech-to-Text Service
AssemblyAI Python SDK kullanarak konuÅŸma tanÄ±ma ve transkript oluÅŸturma servisi
KiÅŸi ayrÄ±mÄ± (speaker diarization) desteÄŸi ile profesyonel toplantÄ± transkriptleri

KURULUM:
1. .env dosyasÄ±na ASSEMBLYAI_API_KEY ekleyin
2. pip install assemblyai
3. Speech Model: "universal" (varsayÄ±lan, diÄŸer modeller de desteklenir)

KÄ°ÅÄ° AYRIMI (SPEAKER DIARIZATION):
- AssemblyAI iÃ§in speaker diarization otomatik desteklenir (enable_speaker_labels=True)
- API kendi diarization saÄŸlÄ±yor, harici pyannote sonuÃ§larÄ± ile birleÅŸtirilebilir
"""
import os
import asyncio
from typing import List, Dict, Optional
import assemblyai as aai
from ..config import settings


class AssemblyAIService:
    """AssemblyAI Speech-to-Text servisi - KiÅŸi ayrÄ±mÄ± destekli"""
    
    def __init__(self):
        # AssemblyAI API key - config'den veya environment variable'dan alÄ±nacak
        self.api_key = settings.assemblyai_api_key or os.getenv("ASSEMBLYAI_API_KEY", "")
        
        if not self.api_key:
            raise RuntimeError("AssemblyAI API key bulunamadÄ±. LÃ¼tfen .env dosyasÄ±na ASSEMBLYAI_API_KEY ekleyin.")
        
        # AssemblyAI API key'i ayarla
        aai.settings.api_key = self.api_key
        print(f"âœ… AssemblyAI client oluÅŸturuldu")
    
    async def transcribe_audio(
        self,
        audio_path: str,
        model_name: str = "assemblyai",
        language: str = "tr",
        enable_speaker_diarization: bool = True,
        speaker_segments: Optional[List[Dict]] = None
    ) -> List[Dict]:
        """
        Ses dosyasÄ±nÄ± AssemblyAI SDK kullanarak transkript et
        
        Args:
            audio_path: Ä°ÅŸlenecek ses dosyasÄ± yolu
            model_name: Model adÄ± (assemblyai)
            language: Dil kodu (tr, en) - AssemblyAI otomatik algÄ±lar
            enable_speaker_diarization: KiÅŸi ayrÄ±mÄ± aktif mi
            speaker_segments: Ã–nceden hesaplanmÄ±ÅŸ konuÅŸmacÄ± segmentleri (opsiyonel)
        
        Returns:
            Transkript segmentleri listesi (speaker bilgisi ile)
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"Ses dosyasÄ± bulunamadÄ±: {audio_path}")
        
        # Dosya bilgilerini kontrol et
        file_size = os.path.getsize(audio_path)
        print(f"ğŸ“Š AssemblyAI: Dosya boyutu: {file_size} bytes ({file_size / 1024:.2f} KB)")
        
        if file_size < 1000:  # 1KB'dan kÃ¼Ã§Ã¼kse
            print("âš ï¸  AssemblyAI: Dosya Ã§ok kÃ¼Ã§Ã¼k, muhtemelen boÅŸ")
            return [{
                "text": "",
                "start": 0.0,
                "end": 0.0,
                "speaker_id": None,
                "speaker_label": None
            }]
        
        print(f"ğŸŒ AssemblyAI: Dil: {language} (otomatik algÄ±lama)")
        
        try:
            # TranscriptionConfig oluÅŸtur
            print(f"ğŸ“‚ AssemblyAI: Ses dosyasÄ± okunuyor: {audio_path}")
            print(f"ğŸ“‹ AssemblyAI: Speaker Diarization: {enable_speaker_diarization}")
            
            config = aai.TranscriptionConfig(
                speech_model=aai.SpeechModel.best,  # En iyi kalite iÃ§in 'best' modeli
                speaker_labels=enable_speaker_diarization,  # KiÅŸi ayrÄ±mÄ±
                language_code=language if language in ["tr", "en"] else None,  # Otomatik algÄ±lama iÃ§in None
                punctuate=True,  # Noktalama iÅŸaretleri ekle
                format_text=True,  # Metni formatla (bÃ¼yÃ¼k harf, vb.)
                language_detection=True,  # Otomatik dil algÄ±lama
                # TÃ¼rkÃ§e iÃ§in Ã¶zel ayarlar
                speech_threshold=0.5,  # KonuÅŸma algÄ±lama eÅŸiÄŸi (0.0-1.0, dÃ¼ÅŸÃ¼k = daha hassas)
            )
            
            # SDK metodunu async executor'da Ã§alÄ±ÅŸtÄ±r
            def _transcribe():
                transcriber = aai.Transcriber(config=config)
                return transcriber.transcribe(audio_path)
            
            # Senkron SDK metodunu async executor'da Ã§alÄ±ÅŸtÄ±r
            try:
                transcript = await asyncio.to_thread(_transcribe)
            except AttributeError:
                # Python < 3.9 iÃ§in alternatif
                loop = asyncio.get_event_loop()
                transcript = await loop.run_in_executor(None, _transcribe)
            
            # Hata kontrolÃ¼
            if transcript.status == "error":
                error_msg = f"AssemblyAI transcription failed: {transcript.error}"
                print(f"âŒ {error_msg}")
                raise RuntimeError(error_msg)
            
            print(f"âœ… AssemblyAI: Transkript alÄ±ndÄ± (Status: {transcript.status})")
            
            # Debug: Transcript objesinin yapÄ±sÄ±nÄ± kontrol et
            print(f"ğŸ” Debug: Transcript objesi tipi: {type(transcript)}")
            print(f"ğŸ” Debug: Transcript attributes: {dir(transcript)}")
            print(f"ğŸ” Debug: Has utterances: {hasattr(transcript, 'utterances')}")
            if hasattr(transcript, 'utterances'):
                print(f"ğŸ” Debug: Utterances var mÄ±: {transcript.utterances is not None}")
                print(f"ğŸ” Debug: Utterances tipi: {type(transcript.utterances)}")
                if transcript.utterances:
                    print(f"ğŸ” Debug: Utterances sayÄ±sÄ±: {len(transcript.utterances)}")
                    if len(transcript.utterances) > 0:
                        print(f"ğŸ” Debug: Ä°lk utterance: {transcript.utterances[0]}")
                        print(f"ğŸ” Debug: Ä°lk utterance attributes: {dir(transcript.utterances[0]) if hasattr(transcript.utterances[0], '__dict__') else 'N/A'}")
            print(f"ğŸ” Debug: Has words: {hasattr(transcript, 'words')}")
            if hasattr(transcript, 'words') and transcript.words:
                print(f"ğŸ” Debug: Words sayÄ±sÄ±: {len(transcript.words)}")
                if len(transcript.words) > 0:
                    print(f"ğŸ” Debug: Ä°lk word: {transcript.words[0]}")
            
            # API yanÄ±tÄ±nÄ± iÅŸle
            segments = self._process_api_response(
                transcript,
                enable_speaker_diarization,
                speaker_segments
            )
            
            return segments
        
        except Exception as e:
            error_msg = f"AssemblyAI iÅŸleme hatasÄ±: {e}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            raise RuntimeError(error_msg)
    
    def _process_api_response(
        self,
        transcript,
        enable_speaker_diarization: bool,
        speaker_segments: Optional[List[Dict]] = None
    ) -> List[Dict]:
        """
        AssemblyAI transcript objesini iÅŸle ve segmentlere dÃ¶nÃ¼ÅŸtÃ¼r
        
        AssemblyAI transcript objesi ÅŸu Ã¶zelliklere sahiptir:
        - transcript.text: Tam metin
        - transcript.utterances: KonuÅŸmacÄ± bazlÄ± segmentler (speaker_labels=True ise)
        - transcript.words: Kelime bazlÄ± zaman damgalarÄ±
        """
        segments = []
        
        # Utterances varsa (speaker diarization aktifse) onlarÄ± kullan
        if enable_speaker_diarization and hasattr(transcript, 'utterances') and transcript.utterances:
            print(f"ğŸ¤ AssemblyAI: {len(transcript.utterances)} utterance bulundu")
            for utterance in transcript.utterances:
                # Utterance'dan bilgileri al (dict veya obje olabilir)
                if isinstance(utterance, dict):
                    utterance_text = utterance.get('text', '')
                    utterance_start = utterance.get('start', 0)
                    utterance_end = utterance.get('end', 0)
                    utterance_speaker = utterance.get('speaker', None)
                else:
                    utterance_text = getattr(utterance, 'text', '')
                    utterance_start = getattr(utterance, 'start', 0)
                    utterance_end = getattr(utterance, 'end', 0)
                    # Speaker bilgisi farklÄ± attribute'larda olabilir
                    utterance_speaker = getattr(utterance, 'speaker', None) or getattr(utterance, 'speaker_label', None)
                
                # AssemblyAI utterances iÃ§in zaman damgalarÄ± genelde saniye cinsindendir (milisaniye deÄŸil)
                # Ama 100000'den bÃ¼yÃ¼kse milisaniye olabilir
                if utterance_start > 100000:
                    start_sec = utterance_start / 1000.0  # Milisaniyeden saniyeye
                else:
                    start_sec = utterance_start
                
                if utterance_end > 100000:
                    end_sec = utterance_end / 1000.0  # Milisaniyeden saniyeye
                else:
                    end_sec = utterance_end
                
                # Speaker ID'yi dÃ¼zenle - AssemblyAI "A", "B" veya "SPEAKER_00", "SPEAKER_01" formatÄ±nda olabilir
                if utterance_speaker is not None:
                    speaker_str = str(utterance_speaker)
                    # EÄŸer "A", "B" gibi harf formatÄ±ndaysa
                    if len(speaker_str) == 1 and speaker_str.isalpha():
                        speaker_id = f"speaker_{ord(speaker_str) - ord('A')}"
                    # EÄŸer "SPEAKER_00" formatÄ±ndaysa
                    elif speaker_str.startswith('SPEAKER_'):
                        speaker_num = speaker_str.replace('SPEAKER_', '').strip()
                        speaker_id = f"speaker_{speaker_num}"
                    # EÄŸer zaten "speaker_" ile baÅŸlÄ±yorsa
                    elif speaker_str.startswith('speaker_'):
                        speaker_id = speaker_str
                    # DiÄŸer durumlar
                    else:
                        speaker_id = f"speaker_{speaker_str}"
                else:
                    speaker_id = None
                
                print(f"ğŸ” Debug utterance: text='{utterance_text[:50]}...', start={start_sec}, end={end_sec}, speaker={utterance_speaker}, speaker_id={speaker_id}")
                
                segments.append({
                    'text': utterance_text,
                    'start': start_sec,
                    'end': end_sec,
                    'speaker_id': speaker_id,
                    'speaker_label': self._get_speaker_label(speaker_id) if speaker_id else None
                })
        # Utterances yoksa ama words varsa, words'den segment oluÅŸtur (speaker bilgisi ile)
        elif hasattr(transcript, 'words') and transcript.words:
            print(f"ğŸ“ AssemblyAI: Words'den segment oluÅŸturuluyor ({len(transcript.words)} kelime)")
            # Kelimeleri zaman damgasÄ±na gÃ¶re sÄ±rala
            words_list = list(transcript.words)
            
            def get_word_start(w):
                if isinstance(w, dict):
                    return w.get('start', 0)
                return getattr(w, 'start', 0)
            
            words_list.sort(key=get_word_start)
            
            if not words_list:
                # EÄŸer kelime yoksa ama text varsa, tek segment oluÅŸtur
                transcript_text = transcript.text if hasattr(transcript, 'text') else ""
                if transcript_text:
                    segments.append({
                        'text': transcript_text,
                        'start': 0.0,
                        'end': 0.0,
                        'speaker_id': None,
                        'speaker_label': None
                    })
                return segments
            
            # Words'den speaker bilgisi var mÄ± kontrol et
            first_word = words_list[0]
            has_speaker_in_words = False
            if isinstance(first_word, dict):
                has_speaker_in_words = 'speaker' in first_word or 'speaker_label' in first_word
            else:
                has_speaker_in_words = hasattr(first_word, 'speaker') or hasattr(first_word, 'speaker_label')
            
            # EÄŸer words'de speaker bilgisi varsa, speaker'a gÃ¶re grupla
            if enable_speaker_diarization and has_speaker_in_words:
                print(f"ğŸ¤ AssemblyAI: Words'de speaker bilgisi bulundu, gruplandÄ±rÄ±lÄ±yor...")
                current_speaker = None
                current_text = []
                current_start = 0.0
                current_end = 0.0
                
                for word in words_list:
                    # Word'dan bilgileri al
                    if isinstance(word, dict):
                        word_text = word.get('text', '')
                        word_start = word.get('start', 0)
                        word_end = word.get('end', 0)
                        word_speaker = word.get('speaker') or word.get('speaker_label')
                    else:
                        word_text = getattr(word, 'text', '')
                        word_start = getattr(word, 'start', 0)
                        word_end = getattr(word, 'end', 0)
                        word_speaker = getattr(word, 'speaker', None) or getattr(word, 'speaker_label', None)
                    
                    # Zaman damgalarÄ±nÄ± saniyeye Ã§evir (gerekirse)
                    if word_start > 100000:
                        word_start = word_start / 1000.0
                    if word_end > 100000:
                        word_end = word_end / 1000.0
                    
                    # Speaker ID'yi dÃ¼zenle
                    if word_speaker is not None:
                        speaker_str = str(word_speaker)
                        if len(speaker_str) == 1 and speaker_str.isalpha():
                            speaker_id = f"speaker_{ord(speaker_str) - ord('A')}"
                        elif speaker_str.startswith('SPEAKER_'):
                            speaker_num = speaker_str.replace('SPEAKER_', '').strip()
                            speaker_id = f"speaker_{speaker_num}"
                        elif speaker_str.startswith('speaker_'):
                            speaker_id = speaker_str
                        else:
                            speaker_id = f"speaker_{speaker_str}"
                    else:
                        speaker_id = None
                    
                    # Speaker deÄŸiÅŸti mi?
                    if speaker_id != current_speaker:
                        # Ã–nceki speaker'Ä±n segmentini kaydet
                        if current_text:
                            segments.append({
                                'text': ' '.join(current_text),
                                'start': current_start,
                                'end': current_end,
                                'speaker_id': current_speaker,
                                'speaker_label': self._get_speaker_label(current_speaker) if current_speaker else None
                            })
                        # Yeni speaker baÅŸlat
                        current_speaker = speaker_id
                        current_text = [word_text] if word_text else []
                        current_start = word_start
                        current_end = word_end
                    else:
                        # AynÄ± speaker devam ediyor
                        if word_text:
                            current_text.append(word_text)
                        current_end = word_end
                
                # Son segmenti ekle
                if current_text:
                    segments.append({
                        'text': ' '.join(current_text),
                        'start': current_start,
                        'end': current_end,
                        'speaker_id': current_speaker,
                        'speaker_label': self._get_speaker_label(current_speaker) if current_speaker else None
                    })
            else:
                # Speaker bilgisi yok, tÃ¼m kelimeleri birleÅŸtir
                first_word = words_list[0]
                last_word = words_list[-1]
                
                # Zaman damgalarÄ±nÄ± al
                if isinstance(first_word, dict):
                    first_start = first_word.get('start', 0)
                    last_end = last_word.get('end', 0)
                else:
                    first_start = getattr(first_word, 'start', 0)
                    last_end = getattr(last_word, 'end', 0)
                
                # Milisaniye ise saniyeye Ã§evir
                start_time = first_start / 1000.0 if first_start > 100000 else first_start
                end_time = last_end / 1000.0 if last_end > 100000 else (last_end if last_end > 0 else start_time + 1.0)
                
                # TÃ¼m kelimeleri birleÅŸtir
                text_parts = []
                for word in words_list:
                    word_text = word.get('text', '') if isinstance(word, dict) else getattr(word, 'text', '')
                    if word_text:
                        text_parts.append(word_text)
                
                transcript_text = transcript.text if hasattr(transcript, 'text') else ""
                full_text = ' '.join(text_parts) if text_parts else transcript_text
                
                segments.append({
                    'text': full_text,
                    'start': start_time,
                    'end': end_time,
                    'speaker_id': None,
                    'speaker_label': None
                })
        # HiÃ§biri yoksa ama text varsa
        elif hasattr(transcript, 'text') and transcript.text:
            print(f"ğŸ“„ AssemblyAI: Tek metin segmenti oluÅŸturuluyor")
            segments.append({
                'text': transcript.text,
                'start': 0.0,
                'end': 0.0,
                'speaker_id': None,
                'speaker_label': None
            })
        else:
            print("âš ï¸  AssemblyAI: HiÃ§ transkript verisi bulunamadÄ±")
            return []
        
        # EÄŸer speaker_segments varsa ve API'den speaker bilgisi gelmemiÅŸse, eÅŸleÅŸtir
        if enable_speaker_diarization and speaker_segments and not any(seg.get("speaker_id") for seg in segments):
            print("ğŸ”„ AssemblyAI: Harici speaker diarization sonuÃ§larÄ± ile eÅŸleÅŸtiriliyor...")
            for segment in segments:
                for speaker_seg in speaker_segments:
                    if (segment["start"] >= speaker_seg["start"] and 
                        segment["end"] <= speaker_seg["end"]):
                        segment["speaker_id"] = speaker_seg.get("speaker_id")
                        segment["speaker_label"] = speaker_seg.get("speaker_label")
                        break
        
        # Speaker bilgisi yoksa ve diarization aktifse, label'larÄ± oluÅŸtur
        if enable_speaker_diarization:
            for segment in segments:
                if segment.get("speaker_id") and not segment.get("speaker_label"):
                    segment["speaker_label"] = self._get_speaker_label(segment["speaker_id"])
        
        print(f"âœ… AssemblyAI: {len(segments)} transkript segmenti oluÅŸturuldu")
        return segments
    
    def _get_speaker_label(self, speaker_id: str) -> str:
        """Speaker ID'yi okunabilir etikete Ã§evir"""
        if not speaker_id or speaker_id == 'speaker_unknown':
            return None
        
        try:
            # speaker_0, speaker_1 formatÄ±
            if speaker_id.startswith('speaker_'):
                speaker_num = int(speaker_id.split('_')[1])
                return f"KonuÅŸmacÄ± {speaker_num + 1}"
            # Direkt sayÄ±
            elif speaker_id.isdigit():
                return f"KonuÅŸmacÄ± {int(speaker_id) + 1}"
            else:
                return speaker_id
        except:
            return speaker_id

